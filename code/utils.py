# ======================================================
# utils.py | é€šç”¨å·¥å…·å‡½æ•°åˆé›† (è®­ç»ƒ + è¯„ä¼° + å¯è§†åŒ– + æ•ˆç‡)
# ======================================================

import os
import time
import json
import torch
import numpy as np
import matplotlib.pyplot as plt
from math import log10
from pytorch_msssim import ssim
import timm
import pandas as pd
# ======================================================
# âœ… åŸºç¡€è®­ç»ƒä¸éªŒè¯å‡½æ•°
# ======================================================
def train_one_epoch(model, loader, criterion, optimizer, device):
    model.train()
    total_loss = 0.0
    for x, y in loader:
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        outputs = model(x)
        loss = criterion(outputs, y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item() * x.size(0)
    return total_loss / len(loader.dataset)


def evaluate(model, loader, criterion, device, is_test=False):
    model.eval()
    total_loss, correct, total = 0.0, 0, 0
    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(device), y.to(device)
            outputs = model(x)
            loss = criterion(outputs, y)
            total_loss += loss.item() * x.size(0)
            _, pred = outputs.max(1)
            correct += pred.eq(y).sum().item()
            total += y.size(0)
    acc = 100. * correct / total
    if is_test:
        print(f"ğŸ¯ Test: Loss={total_loss / len(loader.dataset):.4f}, Acc={acc:.2f}%")
    return total_loss / len(loader.dataset), acc


# ======================================================
# âœ… ç»˜åˆ¶åˆ†ç±»ä»»åŠ¡è®­ç»ƒæ›²çº¿ (Loss + Accuracy)
# ======================================================
def plot_curves(train_losses, val_losses, val_accuracies, save_path=None):
    epochs = range(1, len(train_losses) + 1)
    plt.figure(figsize=(10, 4))

    plt.subplot(1, 2, 1)
    plt.plot(epochs, train_losses, label="Train Loss", linewidth=2)
    plt.plot(epochs, val_losses, label="Val Loss", linewidth=2)
    plt.xlabel("Epoch"); plt.ylabel("Loss"); plt.legend()
    plt.title("Training & Validation Loss"); plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(epochs, val_accuracies, label="Val Accuracy", color="orange", linewidth=2)
    plt.xlabel("Epoch"); plt.ylabel("Accuracy (%)"); plt.legend()
    plt.title("Validation Accuracy"); plt.grid(True)

    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, dpi=300)
        plt.close()
        print(f"ğŸ“Š åˆ†ç±»æ›²çº¿å›¾å·²ä¿å­˜è‡³ {save_path}")
    else:
        plt.show()


# ======================================================
# âœ… ç»˜åˆ¶é‡å»ºä»»åŠ¡æ›²çº¿ (Loss + PSNR + SSIM)
# ======================================================
def plot_reconstruction_metrics(train_losses, psnr_scores, ssim_scores, task_name, output_dir):
    epochs = range(1, len(train_losses) + 1)
    plt.figure(figsize=(10, 4))

    plt.subplot(1, 3, 1)
    plt.plot(epochs, train_losses, label="Train Loss", linewidth=2, color="tab:blue")
    plt.xlabel("Epoch"); plt.ylabel("MSE Loss"); plt.grid(True)
    plt.title(f"{task_name} Training Loss")

    plt.subplot(1, 3, 2)
    plt.plot(epochs, psnr_scores, label="PSNR", linewidth=2, color="tab:green")
    plt.xlabel("Epoch"); plt.ylabel("PSNR (dB)"); plt.grid(True)
    plt.title("Validation PSNR")

    plt.subplot(1, 3, 3)
    plt.plot(epochs, ssim_scores, label="SSIM", linewidth=2, color="tab:red")
    plt.xlabel("Epoch"); plt.ylabel("SSIM"); plt.grid(True)
    plt.title("Validation SSIM")

    plt.tight_layout()
    save_path = f"{output_dir}/{task_name.lower()}_metrics_curve.png"
    plt.savefig(save_path, dpi=300)
    plt.close()
    print(f"ğŸ“ˆ å·²ä¿å­˜ {task_name} æ›²çº¿å›¾ â†’ {save_path}")


# ======================================================
# âœ… è®¡ç®—å›¾åƒè´¨é‡æŒ‡æ ‡ (PSNR + SSIM)
# ======================================================
def compute_metrics(pred, target):
    mse = torch.mean((pred - target) ** 2).item()
    psnr = 20 * log10(1.0 / (mse ** 0.5 + 1e-8))
    ssim_val = ssim(pred.unsqueeze(0), target.unsqueeze(0),
                    data_range=1.0, size_average=True).item()
    return psnr, ssim_val


# ======================================================
# âœ… è®¡æ—¶è£…é¥°å™¨
# ======================================================
def timer(func):
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        end = time.time()
        print(f"â±ï¸ {func.__name__} æ€»è€—æ—¶: {(end - start)/60:.2f} min")
        return result
    return wrapper

# ------------------------------------------------------
# â±ï¸ è®­ç»ƒæ—¶é—´ & æ¨ç†é€Ÿåº¦
# ------------------------------------------------------
def measure_training_time(func, *args, **kwargs):
    start = time.time()
    output = func(*args, **kwargs)
    end = time.time()
    return output, round((end - start) / 60.0, 2)


def measure_inference_speed(model_path, dataloader, device="cuda", n_images=100):
    """
    æµ‹é‡æ¨¡å‹æ¨ç†é€Ÿåº¦ (ç§’ / 100 å¼ å›¾ç‰‡)
    âœ… è‡ªåŠ¨è¯†åˆ« state_dict å¹¶é‡å»º ViT æ¨¡å‹ç»“æ„
    âœ… ä½¿ç”¨ torch.cuda.synchronize() ç¡®ä¿è®¡æ—¶å‡†ç¡®
    """

    if not os.path.exists(model_path):
        print(f"âš ï¸ æœªæ‰¾åˆ°æ¨¡å‹æƒé‡: {model_path}")
        return None

    state = torch.load(model_path, map_location=device)

    # âœ… è‹¥æ˜¯ state_dictï¼Œåˆ™è‡ªåŠ¨é‡å»º ViT Tiny æ¨¡å‹
    if isinstance(state, dict):
        print(f"ğŸ”§ æ£€æµ‹åˆ° state_dictï¼Œè‡ªåŠ¨æ„å»º ViT æ¨¡å‹ç”¨äºæ¨ç†æµ‹é€Ÿ...")
        model = timm.create_model(
            "vit_tiny_patch16_224",
            pretrained=False,
            img_size=32, patch_size=4,
            num_classes=100
        ).to(device)
        model.load_state_dict(state, strict=False)
    else:
        model = state.to(device)

    model.eval()

    imgs_list = []
    for imgs, _ in dataloader:
        imgs_list.append(imgs)
        if sum([b.size(0) for b in imgs_list]) >= n_images:
            break
    imgs = torch.cat(imgs_list)[:n_images].to(device)

    # âœ… åŒæ­¥ CUDA æµï¼Œç¡®ä¿æ—¶é—´æµ‹é‡å‡†ç¡®
    torch.cuda.synchronize() if device == "cuda" else None
    start = time.time()

    with torch.no_grad():
        _ = model(imgs)

    torch.cuda.synchronize() if device == "cuda" else None
    end = time.time()

    elapsed = round(end - start, 3)
    print(f"âš¡ æ¨ç†æ—¶é—´: {elapsed:.3f} s / 100 images ({os.path.basename(model_path)})")

    return elapsed

# ------------------------------------------------------
# ğŸ“Š ç»˜åˆ¶ æ•°æ®è§„æ¨¡ vs ç²¾åº¦ æ›²çº¿
# ------------------------------------------------------
def plot_data_scale(csv_path="./outputs/data_scale.csv",
                    save_path="./outputs/plot_data_scale.png"):
    if not os.path.exists(csv_path):
        print(f"âŒ æœªæ‰¾åˆ° {csv_path}")
        return
    df = pd.read_csv(csv_path).sort_values("DataRatio")
    plt.figure(figsize=(6, 4))
    plt.plot(df["DataRatio"], df["Accuracy(%)"], marker="o", linewidth=2.2)
    plt.grid(True, linestyle="--", alpha=0.6)
    plt.title("MAE Pretraining Data Scale vs Classification Accuracy")
    plt.xlabel("Training Data Ratio"); plt.ylabel("Accuracy (%)")
    plt.xticks(df["DataRatio"], [f"{r*100:.0f}%" for r in df["DataRatio"]])
    plt.tight_layout()
    plt.savefig(save_path, dpi=300)
    plt.close()
    print(f"âœ… æ•°æ®è§„æ¨¡æ›²çº¿å·²ä¿å­˜è‡³ {save_path}")

'''
# ======================================================
# âœ… ä¿å­˜æ•ˆç‡æŒ‡æ ‡ (JSON)
# ======================================================
def record_efficiency(train_time_min, inference_time_s, acc_gain,
                      save_path="./outputs/efficiency.json"):
    result = {
        "Training Time (min)": round(train_time_min, 2),
        "Inference Time (s / 100 images)": round(inference_time_s, 3),
        "Accuracy Gain (%)": round(acc_gain, 2)
    }
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    with open(save_path, "w", encoding="utf-8") as f:
        json.dump(result, f, indent=4, ensure_ascii=False)
    print(f"âœ… è®­ç»ƒæ•ˆç‡ç»“æœå·²ä¿å­˜è‡³ {save_path}")
'''