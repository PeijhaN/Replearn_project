# ======================================================
# tasks_multitask.py | ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒ (ä¸Šè‰² + å»å™ª + è´¨é‡æŒ‡æ ‡ + å¯è§†åŒ–)
# ======================================================

import os
import json
import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
from torchvision.utils import save_image
from torch.utils.tensorboard import SummaryWriter
import timm
from finetune_classification import detect_pretrain_type
from utils import compute_metrics, plot_reconstruction_metrics
from config_data import get_cifar100


# ======================================================
# ä¸Šè‰²ä¸å»å™ªè§£ç å™¨
# ======================================================
class ColorizationHead(nn.Module):
    def __init__(self, embed_dim=192):
        super().__init__()
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(embed_dim, 128, 4, 2, 1),
            nn.BatchNorm2d(128), nn.ReLU(True),
            nn.ConvTranspose2d(128, 64, 4, 2, 1),
            nn.BatchNorm2d(64), nn.ReLU(True),
            nn.Conv2d(64, 3, 3, 1, 1),
            nn.Sigmoid()
        )

    def forward(self, feats_2d):
        return self.decoder(feats_2d)


class DenoisingHead(nn.Module):
    def __init__(self, embed_dim=192):
        super().__init__()
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(embed_dim, 128, 4, 2, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(128, 64, 4, 2, 1),
            nn.ReLU(True),
            nn.Conv2d(64, 3, 3, 1, 1),
            nn.Sigmoid()
        )

    def forward(self, feats_2d):
        return self.decoder(feats_2d)


# ======================================================
# åŠ è½½é¢„è®­ç»ƒ Encoder
# ======================================================
def load_pretrained_encoder(pretrain_path, device):
    ptype = detect_pretrain_type(pretrain_path)
    if ptype == "MAE":
        from models_mae import MaskedAutoencoderViT
        encoder = MaskedAutoencoderViT().encoder.to(device)
    else:
        encoder = timm.create_model(
            'vit_tiny_patch16_224',
            pretrained=False,
            img_size=32,
            patch_size=4,
            num_classes=0,
            global_pool='token'
        ).to(device)

    if pretrain_path and os.path.exists(pretrain_path):
        state = torch.load(pretrain_path, map_location=device)
        if isinstance(state, dict) and 'encoder' in state:
            encoder.load_state_dict(state['encoder'], strict=False)
        else:
            encoder.load_state_dict(state, strict=False)
        print(f"âœ… Encoder æƒé‡åŠ è½½è‡ª {pretrain_path}")
    return encoder, ptype


# ======================================================
# é€šç”¨é‡å»ºä»»åŠ¡è®­ç»ƒå‡½æ•°ï¼ˆä¸Šè‰²/å»å™ªï¼‰
# ======================================================
def train_reconstruction_task(task_name, encoder, decoder,
                              train_loader, val_loader,
                              output_dir, device, epochs=80):
    os.makedirs(output_dir, exist_ok=True)

    base = os.path.basename(output_dir)
    writer_log_dir = f'./outputs/tensorboard/{base}'

    writer = SummaryWriter(log_dir = writer_log_dir)

    #writer = SummaryWriter(log_dir=f"{output_dir}/tensorboard_{task_name}")

    criterion = nn.MSELoss()
    optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-4)

    train_losses, psnr_scores, ssim_scores = [], [], []

    for epoch in range(epochs):
        encoder.train()
        decoder.train()
        total_loss = 0.0

        for imgs, _ in tqdm(train_loader, desc=f"[{task_name}] Epoch {epoch+1}/{epochs}"):
            imgs = imgs.to(device)
            # === è¾“å…¥æ„é€  ===
            if task_name == "Colorization":
                inputs = imgs.mean(dim=1, keepdim=True).repeat(1, 3, 1, 1)
            elif task_name == "Denoising":
                noise = torch.randn_like(imgs) * 0.2
                inputs = torch.clamp(imgs + noise, 0, 1)
            else:
                raise ValueError("æœªçŸ¥ä»»åŠ¡ç±»å‹")

            # === å‰å‘ä¼ æ’­ ===
            feats = encoder.forward_features(inputs)
            B, N, D = feats.shape
            if N > 64:
                feats = feats[:, 1:, :]  # å»é™¤ CLS token
            h = w = int(feats.shape[1] ** 0.5)
            feats_2d = feats.permute(0, 2, 1).reshape(B, D, h, w)
            preds = decoder(feats_2d)

            loss = criterion(preds, imgs)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        avg_loss = total_loss / len(train_loader)
        train_losses.append(avg_loss)
        writer.add_scalar("Loss/Train", avg_loss, epoch)

        # ===== éªŒè¯é˜¶æ®µ =====
        encoder.eval(); decoder.eval()
        psnr_epoch, ssim_epoch, count = 0, 0, 0
        with torch.no_grad():
            for imgs, _ in val_loader:
                imgs = imgs.to(device)
                if task_name == "Colorization":
                    inputs = imgs.mean(dim=1, keepdim=True).repeat(1, 3, 1, 1)
                else:
                    noise = torch.randn_like(imgs) * 0.2
                    inputs = torch.clamp(imgs + noise, 0, 1)
                feats = encoder.forward_features(inputs)
                B, N, D = feats.shape
                if N > 64:
                    feats = feats[:, 1:, :]
                h = w = int(feats.shape[1] ** 0.5)
                feats_2d = feats.permute(0, 2, 1).reshape(B, D, h, w)
                preds = decoder(feats_2d)
                for i in range(min(8, imgs.size(0))):
                    ps, ss = compute_metrics(preds[i].cpu(), imgs[i].cpu())
                    psnr_epoch += ps
                    ssim_epoch += ss
                    count += 1
        psnr_epoch /= count
        ssim_epoch /= count
        psnr_scores.append(psnr_epoch)
        ssim_scores.append(ssim_epoch)
        writer.add_scalar("PSNR/Val", psnr_epoch, epoch)
        writer.add_scalar("SSIM/Val", ssim_epoch, epoch)

        print(f"ğŸ“Š {task_name} | Epoch {epoch+1}: Loss={avg_loss:.4f}, PSNR={psnr_epoch:.2f}, SSIM={ssim_epoch:.4f}")

    writer.close()
    plot_reconstruction_metrics(train_losses, psnr_scores, ssim_scores, task_name, output_dir)

    
    # âœ… ä¿å­˜æ ·ä¾‹å›¾åƒå¯¹æ¯”ï¼ˆä½¿ç”¨æœªå¢å¼ºæ•°æ®ï¼‰
  
    with torch.no_grad():
        # åŠ è½½æ— å¢å¼ºç‰ˆæœ¬çš„æ•°æ®
        _, _, clean_loader = get_cifar100(batch_size=8, augment=False)
        clean_imgs, _ = next(iter(clean_loader))
        clean_imgs = clean_imgs.to(device)

        # æ„é€ è¾“å…¥ï¼ˆç°åº¦å›¾æˆ–åŠ å™ªå£°ï¼‰
        if task_name == "Colorization":
            inputs = clean_imgs.mean(dim=1, keepdim=True).repeat(1, 3, 1, 1)
        elif task_name == "Denoising":
            noise = torch.randn_like(clean_imgs) * 0.2
            inputs = torch.clamp(clean_imgs + noise, 0, 1)

        # æ¨¡å‹æ¨ç†
        feats = encoder.forward_features(inputs)
        B, N, D = feats.shape
        if N > 64:
            feats = feats[:, 1:, :]
        h = w = int(feats.shape[1] ** 0.5)
        feats_2d = feats.permute(0, 2, 1).reshape(B, D, h, w)
        preds = decoder(feats_2d)

        # æ‹¼æ¥å¯¹æ¯”ï¼šè¾“å…¥ / è¾“å‡º / åŸå›¾
        grid = torch.cat([inputs.cpu(), preds.cpu(), clean_imgs.cpu()], dim=0)
        save_image(grid, f"{output_dir}/{task_name.lower()}_comparison.png", nrow=8)
        print(f"âœ… {task_name} æ ·ä¾‹å·²ä¿å­˜è‡³ {output_dir}ï¼ˆä½¿ç”¨æœªå¢å¼ºæ•°æ®ï¼‰")

        


        # âœ… ä¿å­˜æœ€ç»ˆæŒ‡æ ‡ JSON
        metrics = {
            "Final Train Loss": round(train_losses[-1], 4),
            "Final PSNR": round(psnr_scores[-1], 3),
            "Final SSIM": round(ssim_scores[-1], 4)
        }
        with open(f"{output_dir}/{task_name.lower()}_metrics.json", "w", encoding="utf-8") as f:
            json.dump(metrics, f, indent=4, ensure_ascii=False)
        print(f"ğŸ“„ {task_name} æŒ‡æ ‡å·²ä¿å­˜ â†’ {output_dir}/{task_name.lower()}_metrics.json")


# ======================================================
# ä¸»å‡½æ•°ï¼šä¸Šè‰²ä¸å»å™ªç‹¬ç«‹å¾®è°ƒ
# ======================================================
def run_multitask_finetune(pretrain_path=None, output_dir="./outputs", epochs=80):
    from config_data import get_cifar100
    train_loader, val_loader, _ = get_cifar100(batch_size=64)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    encoder_color, ptype = load_pretrained_encoder(pretrain_path, device)
    print(f"\nğŸ¨ å¯åŠ¨ä¸Šè‰²ä»»åŠ¡å¾®è°ƒ ({ptype})")
    color_head = ColorizationHead().to(device)
    train_reconstruction_task("Colorization", encoder_color, color_head,
                              train_loader, val_loader,
                              f"{output_dir}/{ptype}_Colorization",
                              device=device, epochs=epochs)

    encoder_denoise, _ = load_pretrained_encoder(pretrain_path, device)
    print(f"\nğŸ§¹ å¯åŠ¨å»å™ªä»»åŠ¡å¾®è°ƒ ({ptype})")
    denoise_head = DenoisingHead().to(device)
    train_reconstruction_task("Denoising", encoder_denoise, denoise_head,
                              train_loader, val_loader,
                              f"{output_dir}/{ptype}_Denoising",
                              device=device, epochs=epochs)

    print(f"\nâœ… {ptype} ä¸‹æ¸¸ä»»åŠ¡ï¼ˆä¸Šè‰² + å»å™ªï¼‰å…¨éƒ¨å®Œæˆ | è¾“å‡ºè·¯å¾„: {output_dir}")
