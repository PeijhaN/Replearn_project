# ======================================================
# main.py | Final Version â€” Self-Supervised Representation Learning Pipeline
# ======================================================

import os
import torch
import pandas as pd
from config_data import get_cifar100
from pretrain_mae import train_mae
from pretrain_rotation import train_rotation
from finetune_classification import finetune_vit
from tasks_multitask import run_multitask_finetune

from visualize_representation import visualize_tsne_umap
from evaluate_representation_metrics import evaluate_representation

from utils import measure_training_time, measure_inference_speed, timer, plot_data_scale


# ======================================================
# è‡ªåŠ¨åˆ›å»ºè¾“å‡ºç›®å½•
# ======================================================
os.makedirs("./outputs/checkpoints", exist_ok=True)
os.makedirs("./outputs/tensorboard", exist_ok=True)
os.makedirs("./outputs", exist_ok=True)


# ======================================================
# ä¸»å‡½æ•°å…¥å£
# ======================================================
def main():
    print("\nğŸš€ Self-Supervised Representation Learning Pipeline Start\n")

    # ======================================================
    # 1ï¸âƒ£ åŠ è½½ CIFAR-100 æ•°æ®
    # ======================================================
    train_loader, val_loader, test_loader = get_cifar100(batch_size=256)
    print(f"âœ… CIFAR-100 æ•°æ®åŠ è½½å®Œæˆ | è®­ç»ƒæ ·æœ¬: {len(train_loader.dataset)}")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    mae_ckpt = "./outputs/checkpoints/mae_vit.pth"
    rot_ckpt = "./outputs/checkpoints/rotation_vit.pth"

    # ======================================================
    # 2ï¸âƒ£ è‡ªç›‘ç£é¢„è®­ç»ƒé˜¶æ®µ (MAE + Rotation)
    # ======================================================
    mae_pretrain_time = rot_pretrain_time = 0.0

    if not os.path.exists(mae_ckpt):
        print("\nğŸ§© å¼€å§‹ MAE è‡ªç›‘ç£é¢„è®­ç»ƒ (200 epochs)")
        _, mae_pretrain_time = measure_training_time(train_mae, train_loader, epochs=150, save_path=mae_ckpt)
    else:
        print("âœ… å·²æ£€æµ‹åˆ° MAE checkpointï¼Œè·³è¿‡é¢„è®­ç»ƒ")

    if not os.path.exists(rot_ckpt):
        print("\nğŸ”„ å¼€å§‹ Rotation è‡ªç›‘ç£é¢„è®­ç»ƒ (150 epochs)")
        _, rot_pretrain_time = measure_training_time(train_rotation, train_loader, epochs=120, save_path=rot_ckpt)
    else:
        print("âœ… å·²æ£€æµ‹åˆ° Rotation checkpointï¼Œè·³è¿‡é¢„è®­ç»ƒ")

    # ======================================================
    # 3ï¸âƒ£ åˆ†ç±»ä»»åŠ¡å¾®è°ƒå¯¹æ¯”ï¼ˆRandom / MAE / Rotationï¼‰
    # ======================================================
    print("\nğŸ¯ åˆ†ç±»ä»»åŠ¡å¾®è°ƒå¯¹æ¯”å®éªŒ")

    baseline_acc = 46.22   # æœ‰ç›‘ç£ViT baseline
    baseline_time = 44.23  # baseline è®­ç»ƒæ—¶é—´ (min)
    results = [("Random (Baseline)", baseline_acc)]

    mae_acc, mae_finetune_time = measure_training_time(
        finetune_vit, train_loader, val_loader, epochs=50,
        pretrain_path=mae_ckpt,
        save_path="./outputs/checkpoints/ft_MAE.pth",
        log_dir="./outputs/tensorboard/ft_MAE"
    )

    rot_acc, rot_finetune_time = measure_training_time(
        finetune_vit, train_loader, val_loader, epochs=50,
        pretrain_path=rot_ckpt,
        save_path="./outputs/checkpoints/ft_Rotation.pth",
        log_dir="./outputs/tensorboard/ft_Rotation"
    )

    results += [("MAE", mae_acc), ("Rotation", rot_acc)]
    df_finetune = pd.DataFrame(results, columns=["Type", "ValAcc(%)"])
    df_finetune.to_csv("./outputs/finetune_compare.csv", index=False)
    print("âœ… åˆ†ç±»ä»»åŠ¡ç»“æœå·²ä¿å­˜è‡³ ./outputs/finetune_compare.csv")

    # ======================================================
    # 4ï¸âƒ£ è¡¨ç¤ºå¯è§†åŒ–ä¸å®šé‡è¯„ä¼°
    # ======================================================
    print("\nğŸ“Š è¡¨ç¤ºå¯è§†åŒ– (Random / Supervised / MAE / Rotation)")
    
    visualize_tsne_umap(num_classes_to_show=100)
    print("\nğŸ“ˆ è¡¨ç¤ºè´¨é‡å®šé‡è¯„ä¼° (KNN / Alignment / Uniformity)")
    evaluate_representation()
    print("âœ… è¡¨ç¤ºè´¨é‡æŒ‡æ ‡å·²å®Œæˆå¹¶è¾“å‡º")

    # ======================================================
    # 5ï¸âƒ£ å¤šä»»åŠ¡ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒï¼ˆä¸Šè‰² + å»å™ªï¼‰
    # ======================================================
    print("\nğŸ§  ä¸‹æ¸¸ä»»åŠ¡ï¼šä¸Šè‰² + å»å™ª (Colorization / Denoising)")
    for name, path in [
        ("MAE", mae_ckpt),
        ("Rotation", rot_ckpt)
    ]:
        run_multitask_finetune(pretrain_path=path,
                               output_dir=f"./outputs/{name}_tasks",
                               epochs=50)
    print("âœ… å¤šä»»åŠ¡ä¸‹æ¸¸ä»»åŠ¡å®Œæˆ")

    # ======================================================
    # 6ï¸âƒ£ æ•°æ®è§„æ¨¡å½±å“å®éªŒ (0.5 Ã— vs 1.0 Ã—)
    # ======================================================

    print("\nğŸ“¦ æ•°æ®è§„æ¨¡å½±å“å®éªŒå¯åŠ¨")
    ratios = [0.3,0.6]

    scale_results = [(1.0, mae_acc)]  # baseline ratio=1 å…ˆåŠ å…¥

    for r in ratios:
        print(f"\nğŸ“‰ å½“å‰æ•°æ®æ¯”ä¾‹: {r}")
        sub_ckpt = f"./outputs/checkpoints/mae_{int(r*100)}.pth"
        tr, vl, _ = get_cifar100(batch_size=128, subset_ratio=r, mode="mae")
           
        if not os.path.exists(sub_ckpt):
           train_mae(tr, epochs=50, save_path=sub_ckpt)

        acc, _ = measure_training_time(
            finetune_vit, tr, vl, epochs=50,
            pretrain_path=sub_ckpt,
            save_path=f"./outputs/checkpoints/ft_MAE_scale_{int(r*100)}.pth",
            log_dir=f"./outputs/tensorboard/ft_MAE_scale_{int(r*100)}"
        )
        scale_results.append((r, acc))

    df_scale = pd.DataFrame(scale_results, columns=["DataRatio", "Accuracy(%)"])
    df_scale.to_csv("./outputs/data_scale.csv", index=False)
    print("âœ… æ•°æ®è§„æ¨¡å®éªŒç»“æœå·²ä¿å­˜è‡³ ./outputs/data_scale.csv")

    # ======================================================
    # 7ï¸âƒ£ è®¡ç®—æ•ˆç‡åˆ†æ (è®­ç»ƒæ—¶é—´ / æ¨ç†é€Ÿåº¦ / ç²¾åº¦æå‡)
    # ======================================================

    print("\nğŸ•’ è®¡ç®—æ•ˆç‡åˆ†æ")

    infer_mae = measure_inference_speed("./outputs/checkpoints/ft_MAE.pth", val_loader, device)
    infer_rot = measure_inference_speed("./outputs/checkpoints/ft_Rotation.pth", val_loader, device)

    infer_random = measure_inference_speed("/workspace/CIFAR_project/runs/cifar100_vit_tiny_aug_20251027_223443/best_model_vit_tiny.pth", val_loader, device)

    efficiency = pd.DataFrame([
        ["Random Init", None, baseline_time, infer_random, baseline_acc],
        ["MAE", mae_pretrain_time, mae_finetune_time, infer_mae, mae_acc],
        ["Rotation", rot_pretrain_time, rot_finetune_time, infer_rot, rot_acc],
    ], columns=["Model", "PretrainTime(min)", "FinetuneTime(min)", "InferTime(s/100)", "Accuracy(%)"])

    efficiency.to_csv("./outputs/efficiency_detail.csv", index=False)
    print("âœ… æ•ˆç‡åˆ†æç»“æœå·²ä¿å­˜è‡³ ./outputs/efficiency_detail.csv")

    # ======================================================
    # 8ï¸âƒ£ ç»˜åˆ¶ æ•°æ®è§„æ¨¡ vs åˆ†ç±»ç²¾åº¦ æ›²çº¿
    # ======================================================
    print("\nğŸ“ˆ ç»˜åˆ¶ MAE é¢„è®­ç»ƒæ•°æ®è§„æ¨¡ vs åˆ†ç±»ç²¾åº¦ æ›²çº¿")
    plot_data_scale("./outputs/data_scale.csv", "./outputs/plot_data_scale.png")

    # ======================================================
    # 9ï¸âƒ£ è¾“å‡ºç»“æœæ±‡æ€»
    # ======================================================
    print("\nâœ… å…¨æµç¨‹å®Œæˆï¼ä¸»è¦è¾“å‡ºæ–‡ä»¶:")
    print(" â”œâ”€ finetune_compare.csv")
    print(" â”œâ”€ data_scale.csv")
    print(" â”œâ”€ plot_data_scale.png")
    print(" â”œâ”€ efficiency_detail.csv")
    print(" â”œâ”€ representation_tsne_umap.png")
    print(" â”œâ”€ MAE_tasks/ & Rotation_tasks/ å›¾åƒè¾“å‡º")
    print(" â””â”€ tensorboard/ æ—¥å¿—")


# ======================================================
# ç¨‹åºå…¥å£
# ======================================================
if __name__ == "__main__":
    main()



